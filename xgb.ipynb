{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.11.2-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.6MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.6a2.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5e/c1/d6/522af54e5cc001fad4dd855117f8bf61b11d56443e06672e26\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.6a2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__MACOSX\n",
      "command.sh\n",
      "download  amazon.ipynb\n",
      "floyd_requirements.txt\n",
      "sample_submission.csv\n",
      "train.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "  0%|          | 0/40479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/input/train-jpg/train_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8b8f5644c1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting train features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting test features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8b8f5644c1a4>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(df, data_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/train-jpg/train_0.jpg'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load data\n",
    "train_path = '/input/train-jpg/'\n",
    "test_path = '/input/test-jpg/'\n",
    "train = pd.read_csv('/input/train.csv')\n",
    "test = pd.read_csv('/input/sample_submission.csv')\n",
    "\n",
    "def extract_features(df, data_path):\n",
    "    im_features = df.copy()\n",
    "\n",
    "    r_mean = []\n",
    "    g_mean = []\n",
    "    b_mean = []\n",
    "\n",
    "    r_std = []\n",
    "    g_std = []\n",
    "    b_std = []\n",
    "\n",
    "    r_max = []\n",
    "    g_max = []\n",
    "    b_max = []\n",
    "\n",
    "    r_min = []\n",
    "    g_min = []\n",
    "    b_min = []\n",
    "\n",
    "    r_kurtosis = []\n",
    "    g_kurtosis = []\n",
    "    b_kurtosis = []\n",
    "    \n",
    "    r_skewness = []\n",
    "    g_skewness = []\n",
    "    b_skewness = []\n",
    "\n",
    "    for image_name in tqdm(im_features.image_name.values, miniters=500): \n",
    "        im = Image.open(data_path + image_name + '.jpg')\n",
    "        im = np.array(im)[:,:,:3]\n",
    "\n",
    "        r_mean.append(np.mean(im[:,:,0].ravel()))\n",
    "        g_mean.append(np.mean(im[:,:,1].ravel()))\n",
    "        b_mean.append(np.mean(im[:,:,2].ravel()))\n",
    "\n",
    "        r_std.append(np.std(im[:,:,0].ravel()))\n",
    "        g_std.append(np.std(im[:,:,1].ravel()))\n",
    "        b_std.append(np.std(im[:,:,2].ravel()))\n",
    "\n",
    "        r_max.append(np.max(im[:,:,0].ravel()))\n",
    "        g_max.append(np.max(im[:,:,1].ravel()))\n",
    "        b_max.append(np.max(im[:,:,2].ravel()))\n",
    "\n",
    "        r_min.append(np.min(im[:,:,0].ravel()))\n",
    "        g_min.append(np.min(im[:,:,1].ravel()))\n",
    "        b_min.append(np.min(im[:,:,2].ravel()))\n",
    "\n",
    "        r_kurtosis.append(scipy.stats.kurtosis(im[:,:,0].ravel()))\n",
    "        g_kurtosis.append(scipy.stats.kurtosis(im[:,:,1].ravel()))\n",
    "        b_kurtosis.append(scipy.stats.kurtosis(im[:,:,2].ravel()))\n",
    "        \n",
    "        r_skewness.append(scipy.stats.skew(im[:,:,0].ravel()))\n",
    "        g_skewness.append(scipy.stats.skew(im[:,:,1].ravel()))\n",
    "        b_skewness.append(scipy.stats.skew(im[:,:,2].ravel()))\n",
    "\n",
    "\n",
    "    im_features['r_mean'] = r_mean\n",
    "    im_features['g_mean'] = g_mean\n",
    "    im_features['b_mean'] = b_mean\n",
    "\n",
    "    im_features['r_std'] = r_std\n",
    "    im_features['g_std'] = g_std\n",
    "    im_features['b_std'] = b_std\n",
    "\n",
    "    im_features['r_max'] = r_max\n",
    "    im_features['g_max'] = g_max\n",
    "    im_features['b_max'] = b_max\n",
    "\n",
    "    im_features['r_min'] = r_min\n",
    "    im_features['g_min'] = g_min\n",
    "    im_features['b_min'] = b_min\n",
    "\n",
    "    im_features['r_kurtosis'] = r_kurtosis\n",
    "    im_features['g_kurtosis'] = g_kurtosis\n",
    "    im_features['b_kurtosis'] = b_kurtosis\n",
    "    \n",
    "    im_features['r_skewness'] = r_skewness\n",
    "    im_features['g_skewness'] = g_skewness\n",
    "    im_features['b_skewness'] = b_skewness\n",
    "    \n",
    "    return im_features\n",
    "\n",
    "# Extract features\n",
    "print('Extracting train features')\n",
    "train_features = extract_features(train, train_path)\n",
    "print('Extracting test features')\n",
    "test_features = extract_features(test, test_path)\n",
    "\n",
    "# Prepare data\n",
    "X = np.array(train_features.drop(['image_name', 'tags'], axis=1))\n",
    "y_train = []\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = np.array(list(set(flatten([l.split(' ') for l in train_features['tags'].values]))))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "for tags in tqdm(train.tags.values, miniters=2000):\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    y_train.append(targets)\n",
    "    \n",
    "y = np.array(y_train, np.uint8)\n",
    "\n",
    "print('X.shape = ' + str(X.shape))\n",
    "print('y.shape = ' + str(y.shape))\n",
    "\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_test = np.array(test_features.drop(['image_name', 'tags'], axis=1))\n",
    "\n",
    "# Train and predict with one-vs-all strategy\n",
    "y_pred = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "print('Training and making predictions')\n",
    "for class_i in tqdm(range(n_classes), miniters=1): \n",
    "#     print('Analysing class ' + str(class_i))\n",
    "    model = xgb.XGBClassifier(max_depth=4, learning_rate=0.3, n_estimators=100, \\\n",
    "                              silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                              subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                              base_score=0.5, seed=random_seed, missing=None)\n",
    "    model.fit(X, y[:, class_i])\n",
    "    y_pred[:, class_i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "preds = [' '.join(labels[y_pred_row > 0.2]) for y_pred_row in y_pred]\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = test_features.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
