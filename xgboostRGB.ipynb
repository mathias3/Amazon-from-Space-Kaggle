{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.11.2-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.6a2.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 341kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/site-packages (from xgboost)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5e/c1/d6/522af54e5cc001fad4dd855117f8bf61b11d56443e06672e26\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.6a2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test-jpg\n",
      "train-jpg\n",
      "train.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "  0%|          | 0/40479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [52:51<00:00, 13.02it/s]  \n",
      "  0%|          | 0/40669 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40669/40669 [57:43<00:00, 11.74it/s]  \n",
      "100%|██████████| 40479/40479 [00:01<00:00, 38173.87it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (40479, 18)\n",
      "y.shape = (40479, 17)\n",
      "Training and making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [15:19<00:00, 46.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "random_seed = 0\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load data\n",
    "train_path = '/input/train-jpg/'\n",
    "test_path = '/input/test-jpg/'\n",
    "train = pd.read_csv('/input/train.csv')\n",
    "test = pd.read_csv('/input/sample_submission.csv')\n",
    "\n",
    "def extract_features(df, data_path):\n",
    "    im_features = df.copy()\n",
    "\n",
    "    r_mean = []\n",
    "    g_mean = []\n",
    "    b_mean = []\n",
    "\n",
    "    r_std = []\n",
    "    g_std = []\n",
    "    b_std = []\n",
    "\n",
    "    r_max = []\n",
    "    g_max = []\n",
    "    b_max = []\n",
    "\n",
    "    r_min = []\n",
    "    g_min = []\n",
    "    b_min = []\n",
    "\n",
    "    r_kurtosis = []\n",
    "    g_kurtosis = []\n",
    "    b_kurtosis = []\n",
    "    \n",
    "    r_skewness = []\n",
    "    g_skewness = []\n",
    "    b_skewness = []\n",
    "\n",
    "    for image_name in tqdm(im_features.image_name.values, miniters=500): \n",
    "        im = Image.open(data_path + image_name + '.jpg')\n",
    "        im = np.array(im)[:,:,:3]\n",
    "\n",
    "        r_mean.append(np.mean(im[:,:,0].ravel()))\n",
    "        g_mean.append(np.mean(im[:,:,1].ravel()))\n",
    "        b_mean.append(np.mean(im[:,:,2].ravel()))\n",
    "\n",
    "        r_std.append(np.std(im[:,:,0].ravel()))\n",
    "        g_std.append(np.std(im[:,:,1].ravel()))\n",
    "        b_std.append(np.std(im[:,:,2].ravel()))\n",
    "\n",
    "        r_max.append(np.max(im[:,:,0].ravel()))\n",
    "        g_max.append(np.max(im[:,:,1].ravel()))\n",
    "        b_max.append(np.max(im[:,:,2].ravel()))\n",
    "\n",
    "        r_min.append(np.min(im[:,:,0].ravel()))\n",
    "        g_min.append(np.min(im[:,:,1].ravel()))\n",
    "        b_min.append(np.min(im[:,:,2].ravel()))\n",
    "\n",
    "        r_kurtosis.append(scipy.stats.kurtosis(im[:,:,0].ravel()))\n",
    "        g_kurtosis.append(scipy.stats.kurtosis(im[:,:,1].ravel()))\n",
    "        b_kurtosis.append(scipy.stats.kurtosis(im[:,:,2].ravel()))\n",
    "        \n",
    "        r_skewness.append(scipy.stats.skew(im[:,:,0].ravel()))\n",
    "        g_skewness.append(scipy.stats.skew(im[:,:,1].ravel()))\n",
    "        b_skewness.append(scipy.stats.skew(im[:,:,2].ravel()))\n",
    "\n",
    "\n",
    "    im_features['r_mean'] = r_mean\n",
    "    im_features['g_mean'] = g_mean\n",
    "    im_features['b_mean'] = b_mean\n",
    "\n",
    "    im_features['r_std'] = r_std\n",
    "    im_features['g_std'] = g_std\n",
    "    im_features['b_std'] = b_std\n",
    "\n",
    "    im_features['r_max'] = r_max\n",
    "    im_features['g_max'] = g_max\n",
    "    im_features['b_max'] = b_max\n",
    "\n",
    "    im_features['r_min'] = r_min\n",
    "    im_features['g_min'] = g_min\n",
    "    im_features['b_min'] = b_min\n",
    "\n",
    "    im_features['r_kurtosis'] = r_kurtosis\n",
    "    im_features['g_kurtosis'] = g_kurtosis\n",
    "    im_features['b_kurtosis'] = b_kurtosis\n",
    "    \n",
    "    im_features['r_skewness'] = r_skewness\n",
    "    im_features['g_skewness'] = g_skewness\n",
    "    im_features['b_skewness'] = b_skewness\n",
    "    \n",
    "    return im_features\n",
    "\n",
    "# Extract features\n",
    "print('Extracting train features')\n",
    "train_features = extract_features(train, train_path)\n",
    "print('Extracting test features')\n",
    "test_features = extract_features(test, test_path)\n",
    "\n",
    "# Prepare data\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(train_features, open('train.pkl', 'wb'), -1)\n",
    "pickle.dump(test_features, open('test.pkl', 'wb'), -1)\n",
    "#pickle.dump(train_features, open('train_features.bin', 'wb'), protocol=4)\n",
    "#pickle.dump(test_features, open('test_features.bin', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 52064.85it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (40479, 18)\n",
      "y.shape = (40479, 17)\n",
      "Training and making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [11:56<00:00, 42.25s/it]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(train_features.drop(['image_name', 'tags'], axis=1))\n",
    "y_train = []\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = np.array(list(set(flatten([l.split(' ') for l in train_features['tags'].values]))))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "\n",
    "for tags in tqdm(train.tags.values, miniters=2000):\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    y_train.append(targets)\n",
    "    \n",
    "y = np.array(y_train, np.uint8)\n",
    "\n",
    "print('X.shape = ' + str(X.shape))\n",
    "print('y.shape = ' + str(y.shape))\n",
    "\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_test = np.array(test_features.drop(['image_name', 'tags'], axis=1))\n",
    "\n",
    "# Train and predict with one-vs-all strategy\n",
    "y_pred = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "print('Training and making predictions')\n",
    "for class_i in tqdm(range(n_classes), miniters=1): \n",
    "#     print('Analysing class ' + str(class_i))\n",
    "    model = xgb.XGBClassifier(max_depth=4, learning_rate=0.3, n_estimators=90, \\\n",
    "                              silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                              subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                              base_score=0.5, seed=random_seed, missing=None)\n",
    "    model.fit(X, y[:, class_i])\n",
    "    y_pred[:, class_i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "preds = [' '.join(labels[y_pred_row > 0.2]) for y_pred_row in y_pred]\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = test_features.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
