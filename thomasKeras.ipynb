{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ef787d4-3b22-a519-cb2e-47e17edb0066"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99508910-31f0-4712-0bb5-c84db0e84f54"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6cef15db-1f07-0c33-bb54-b89b3097b38e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a8c4ac8-c27d-d785-3e58-ea4fd990eed1"
      },
      "outputs": [],
      "source": [
        "filenames = os.listdir('../input/train-jpg')\n",
        "df = pd.read_csv('../input/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66f8e984-b612-1acf-b63d-53f933fe9a31"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a866e67a-16e1-0624-ee6c-ac98132a7418"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "977da6f4-348f-aa8a-c41a-0dae8c8c175a"
      },
      "outputs": [],
      "source": [
        "df['tag_set'] = df['tags'].map(lambda s: set(s.split(' ')))\n",
        "\n",
        "tags = set()\n",
        "for t in df['tags']:\n",
        "    s = set(t.split(' '))\n",
        "    tags = tags | s\n",
        "\n",
        "tag_list = list(tags)\n",
        "tag_list.sort()\n",
        "tag_columns = ['tag_' + t for t in tag_list]\n",
        "for t in tag_list:\n",
        "    df['tag_' + t] = df['tag_set'].map(lambda x: 1 if t in x else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06dd8dcf-3dcd-44d7-21e0-0a9f6040d755"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d411dc7-63c1-b3cb-3a15-9f0280381894"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3aab2a71-8012-5372-8acb-3c0983c0c506"
      },
      "outputs": [],
      "source": [
        "df[tag_columns].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "851ad0fd-9293-aa11-8b9d-c1b478a9e62a"
      },
      "outputs": [],
      "source": [
        "df[tag_columns].sum().sort_values().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d97827d-6fbb-84ba-da9e-b9e9ae29c351"
      },
      "outputs": [],
      "source": [
        "tags_count = df.groupby('tags').count().sort_values(by='image_name', ascending=False)['image_name']\n",
        "print('There are {} unique tag combinations'.format(len(tags_count)))\n",
        "print()\n",
        "print(tags_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "abfb47f9-2e78-dea8-9c97-572c579731c0"
      },
      "outputs": [],
      "source": [
        "from textwrap import wrap\n",
        "\n",
        "def display(images, cols=None, maxcols=10, width=14, titles=None):\n",
        "    if cols is None:\n",
        "        cols = len(images)\n",
        "    n_cols = cols if cols < maxcols else maxcols\n",
        "    plt.rc('axes', grid=False)\n",
        "    fig1 = plt.figure(1, (width, width * math.ceil(len(images)/n_cols)))\n",
        "    grid1 = ImageGrid(\n",
        "                fig1,\n",
        "                111,\n",
        "                nrows_ncols=(math.ceil(len(images)/n_cols), n_cols),\n",
        "                axes_pad=(0.1, 0.6)\n",
        "            )\n",
        "\n",
        "    for index, img in enumerate(images):\n",
        "        grid1[index].grid = False\n",
        "        if titles is not None:\n",
        "            grid1[index].set_title('\\n'.join(wrap(titles[index], width=25)))\n",
        "        if len(img.shape) == 2:\n",
        "            grid1[index].imshow(img, cmap='gray')\n",
        "        else:\n",
        "            grid1[index].imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4f9efa7-6627-ea75-1cf4-d2983ffb1f4b"
      },
      "outputs": [],
      "source": [
        "def load_image(filename, resize=True, folder='train-jpg'):\n",
        "    img = mpimg.imread('../input/{}/{}.jpg'.format(folder, filename))\n",
        "    if resize:\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "    return np.array(img)\n",
        "\n",
        "def mean_normalize(img):\n",
        "    return (img - img.mean()) / (img.max() - img.min())\n",
        "\n",
        "def normalize(img):\n",
        "    return img / 127.5 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6604505-c1cf-669a-5cc3-d53fa60170ce"
      },
      "outputs": [],
      "source": [
        "samples = df.sample(16)\n",
        "sample_images = [load_image(fn) for fn in samples['image_name']]\n",
        "INPUT_SHAPE = sample_images[0].shape\n",
        "print(INPUT_SHAPE)\n",
        "display(\n",
        "    sample_images,\n",
        "    cols=4,\n",
        "    titles=[t for t in samples['tags']]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fde3db34-bfc5-871c-7c0a-d98effb51c47"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "    img = normalize(img)\n",
        "    return img\n",
        "\n",
        "display(\n",
        "    [(127.5 * (preprocess(img) + 1)).astype(np.uint8) for img in sample_images],\n",
        "    cols=4,\n",
        "    titles=[t for t in samples['tags']]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3476a683-d9b8-abfa-0f41-e4d34376270d"
      },
      "source": [
        "# Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7bfe0084-81a9-7c4d-6ecd-e07f23b12511"
      },
      "outputs": [],
      "source": [
        "df_train = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "84bd0c01-4c0f-4921-0cb7-dd7ed704f2ab"
      },
      "outputs": [],
      "source": [
        "X = df_train['image_name'].values\n",
        "y = df_train[tag_columns].values\n",
        "\n",
        "n_features = 1\n",
        "n_classes = y.shape[1]\n",
        "\n",
        "X, y = shuffle(X, y)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "print('We\\'ve got {} feature rows and {} labels'.format(len(X_train), len(y_train)))\n",
        "print('Each row has {} features'.format(n_features))\n",
        "print('and we have {} classes'.format(n_classes))\n",
        "assert(len(y_train) == len(X_train))\n",
        "print('We use {} rows for training and {} rows for validation'.format(len(X_train), len(X_valid)))\n",
        "print('Each image has the shape:', INPUT_SHAPE)\n",
        "print('So far, so good')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7746f07-8533-a624-be6c-a7dda16e97ad"
      },
      "outputs": [],
      "source": [
        "print('Memory usage (train) kB', X_train.nbytes//(1024))\n",
        "print('Memory usage (valid) kB', X_valid.nbytes//(1024))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7d93f36-b75f-2564-2ee3-19a2786ec2b3"
      },
      "outputs": [],
      "source": [
        "def generator(X, y, batch_size=32):\n",
        "    X_copy, y_copy = X, y\n",
        "    while True:\n",
        "        for i in range(0, len(X_copy), batch_size):\n",
        "            X_result, y_result = [], []\n",
        "            for x, y in zip(X_copy[i:i+batch_size], y_copy[i:i+batch_size]):\n",
        "                rx, ry = [load_image(x)], [y]\n",
        "                rx = np.array([preprocess(x) for x in rx])\n",
        "                ry = np.array(ry)\n",
        "                X_result.append(rx)\n",
        "                y_result.append(ry)\n",
        "            X_result, y_result = np.concatenate(X_result), np.concatenate(y_result)\n",
        "            yield shuffle(X_result, y_result)\n",
        "        X_copy, y_copy = shuffle(X_copy, y_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "33af6d60-7e6e-a4d5-6651-11daf350cf91"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def fbeta(y_true, y_pred, threshold_shift=0):\n",
        "    beta = 2\n",
        "\n",
        "    # just in case of hipster activation at the final layer\n",
        "    y_pred = K.clip(y_pred, 0, 1)\n",
        "\n",
        "    # shifting the prediction threshold from .5 if needed\n",
        "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
        "\n",
        "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
        "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    beta_squared = beta ** 2\n",
        "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
        "\n",
        "# ---------------------------------- #\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(48, (8, 8), strides=(2, 2), input_shape=INPUT_SHAPE, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (8, 8), strides=(2, 2), activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(96, (5, 5), strides=(2, 2), activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(n_classes, activation='sigmoid'))\n",
        "\n",
        "    \n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[fbeta, 'accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0561a61b-ee47-d683-39f1-1e814d59a4e8"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 6\n",
        "BATCH = 32\n",
        "PER_EPOCH = 256\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
        "\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_fbeta:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_fbeta', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    generator(X_train, y_train, batch_size=BATCH),\n",
        "    steps_per_epoch=PER_EPOCH,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=generator(X_valid, y_valid, batch_size=BATCH),\n",
        "    validation_steps=len(y_valid)//(4*BATCH),\n",
        "    callbacks=callbacks_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fcd7e82a-798a-b709-f3db-0d93fa621da5"
      },
      "outputs": [],
      "source": [
        "X_test = os.listdir('../input/test-jpg')\n",
        "X_test = [fn.replace('.jpg', '') for fn in X_test]\n",
        "\n",
        "result = []\n",
        "TEST_BATCH = 128\n",
        "for i in range(0, len(X_test), TEST_BATCH):\n",
        "    X_batch = X_test[i:i+TEST_BATCH]\n",
        "    X_batch = np.array([preprocess(load_image(fn, folder='test-jpg')) for fn in X_batch])\n",
        "    p = model.predict(X_batch)\n",
        "    result.append(p)\n",
        "    \n",
        "r = np.concatenate(result)\n",
        "r = r > 0.5\n",
        "\n",
        "table = []\n",
        "for row in r:\n",
        "    t = []\n",
        "    for b, v in zip(row, tag_columns):\n",
        "        if b:\n",
        "            t.append(v.replace('tag_', ''))\n",
        "    table.append(' '.join(t))\n",
        "\n",
        "df_pred = pd.DataFrame.from_dict({'image_name': X_test, 'tags': table})\n",
        "df_pred.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}